{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d76ba7da",
   "metadata": {},
   "source": [
    "# üßôüèª‚Äç‚ôÇÔ∏è GANDALF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc85d13",
   "metadata": {},
   "source": [
    "Gated Adaptive Network for Deep Automated Learning of Features (GANDALF): \n",
    " - [Paper](https://arxiv.org/abs/2207.08548) \n",
    " - [Model](https://pytorch-tabular.readthedocs.io/en/latest/models/#gated-adaptive-network-for-deep-automated-learning-of-features-gandalf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85220f4d",
   "metadata": {},
   "source": [
    "# üì¶ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821c5c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pytorch_tabular\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import wandb\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    ExperimentConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    ")\n",
    "from pytorch_tabular.models import (\n",
    "    GANDALFConfig,\n",
    ")\n",
    "from rich.pretty import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dcf4cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Using device: mps'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Using device: mps'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcatherine-chahrour\u001b[0m (\u001b[33mcatherine-chahrour-university-of-oxford\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Versions: Torch: 2.5.1, PyTorch Tabular: 1.1.1'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Versions: Torch: 2.5.1, PyTorch Tabular: 1.1.1'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "pprint(f\"Using device: {device}\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    pprint(f\"GPU Count: {gpu_count} | GPU Name: {gpu_name}\")\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "pprint(\n",
    "    f\"Versions: Torch: {torch.__version__}, PyTorch Tabular: {pytorch_tabular.__version__}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb74bf14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Project: SEM_MLL-N_TF | Group: GANDALF_SEM_promoters_1024bp_MLL-N_singlelabel_regression'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Project: SEM_MLL-N_TF | Group: GANDALF_SEM_promoters_1024bp_MLL-N_singlelabel_regression'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = \"GANDALF_SEM\"\n",
    "project = \"SEM_MLL-N_TF\"\n",
    "region_name = \"promoters_1024bp\"\n",
    "target = \"MLL-N\"\n",
    "task = \"singlelabel_regression\"\n",
    "start_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "group = f\"{model}_{region_name}_{target}_{task}\"\n",
    "results_dir = f\"results/{project}/{group}_{start_time}\"\n",
    "os.environ[\"WANDB_DIR\"] = f\"{results_dir}\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "pprint(f\"Project: {project} | Group: {group}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cae40c",
   "metadata": {},
   "source": [
    "# üìä Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007ecda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(f\"/Users/catherine/GMS/project/datasets/data_{region_name}/{region_name}.parquet\")\n",
    "\n",
    "for col in data.select_dtypes(include=[\"float64\"]).columns:\n",
    "    data[col] = data[col].astype(\"float32\")\n",
    "\n",
    "meth_cols = [col for col in data.columns if \"METH\" in col]\n",
    "data[meth_cols] = data[meth_cols].fillna(-1)\n",
    "X_data = data[[col for col in data.columns if \"SEM\" in col and target not in col]]\n",
    "y_data = data[[\"SEM_CAT_1_MLL-N\"]]\n",
    "\n",
    "dataset = pd.concat([X_data, y_data], axis=1)\n",
    "\n",
    "train_data = dataset[~dataset.index.str.startswith((\"chr8\", \"chr9\"))]\n",
    "val_data = dataset[dataset.index.str.startswith(\"chr8\")]\n",
    "test_data = dataset[dataset.index.str.startswith(\"chr9\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a819cc",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "587eb90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig(\n",
    "    continuous_cols=[col for col in train_data.columns if target not in col],\n",
    "    continuous_feature_transform=\"quantile_uniform\",\n",
    "    dataloader_kwargs={\"persistent_workers\": True},\n",
    "    normalize_continuous_features=True,\n",
    "    num_workers=10,\n",
    "    pin_memory=True,\n",
    "    target=[col for col in train_data.columns if target in col],\n",
    "    validation_split=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88c6069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "\n",
    "def train():\n",
    "    \"\"\"Trains a model with the hyperparameters defined in the sweep.\"\"\"\n",
    "    if wandb.run is not None:\n",
    "        wandb.finish()\n",
    "    with wandb.init(\n",
    "        name=f\"run_{datetime.datetime.now().strftime('%Y-%m-%d_%H%M')}\",\n",
    "        project=project,\n",
    "        group=group,\n",
    "        job_type=\"sweep\",\n",
    "        dir=f\"{results_dir}/wandb\",\n",
    "        reinit=\"finish_previous\",\n",
    "    ) as run:\n",
    "        config = run.config\n",
    "\n",
    "        trainer_config = TrainerConfig(\n",
    "            accelerator=\"mps\" if device.type == \"mps\" else \"gpu\",\n",
    "            auto_lr_find=True,\n",
    "            batch_size=config.batch_size,\n",
    "            check_val_every_n_epoch=5,\n",
    "            checkpoints_path=f\"{results_dir}/checkpoints\",\n",
    "            early_stopping_mode=\"min\",\n",
    "            early_stopping_patience=3,\n",
    "            early_stopping=\"valid_loss\",\n",
    "            load_best=True,\n",
    "            max_epochs=config.max_epochs,\n",
    "            progress_bar=\"rich\",\n",
    "            trainer_kwargs=dict(enable_model_summary=False),\n",
    "        )\n",
    "\n",
    "        experiment_config = ExperimentConfig(\n",
    "            exp_log_freq=5,\n",
    "            exp_watch=\"gradients\",\n",
    "            log_logits=False,\n",
    "            log_target=\"wandb\",\n",
    "            project_name=project,\n",
    "            run_name=run.name,\n",
    "        )\n",
    "\n",
    "        model_config = GANDALFConfig(\n",
    "            embedding_dropout=config.embedding_dropout,\n",
    "            gflu_dropout=config.gflu_dropout,\n",
    "            gflu_feature_init_sparsity=config.gflu_feature_init_sparsity,\n",
    "            gflu_stages=config.gflu_stages,\n",
    "            head=\"LinearHead\",\n",
    "            loss=\"MSELoss\",\n",
    "            metrics=[\"r2_score\", \"mean_squared_error\"],\n",
    "            metrics_params=[{}] * 2,\n",
    "            seed=42,\n",
    "            target_range=[(0, 1)],\n",
    "            task=\"regression\",\n",
    "        )\n",
    "\n",
    "        model = TabularModel(\n",
    "            data_config=data_config,\n",
    "            experiment_config=experiment_config,\n",
    "            model_config=model_config,\n",
    "            optimizer_config=optimizer_config,\n",
    "            trainer_config=trainer_config,\n",
    "            verbose=False,\n",
    "            suppress_lightning_logger=True,\n",
    "        )\n",
    "\n",
    "        model.fit(train=train_data, validation=val_data)\n",
    "        model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ef5849",
   "metadata": {},
   "source": [
    "# üßπSweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab74dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. lr uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: u4lhvzff\n",
      "Sweep URL: https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/sweeps/u4lhvzff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n9pjob5i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dropout: 0.134332830078693\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgflu_dropout: 0.0127280376735874\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgflu_feature_init_sparsity: 0.2003119120000716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgflu_stages: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 1.0041171739034491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'SEM_MLL-N_TF' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>results/SEM_MLL-N_TF/GANDALF_SEM_promoters_1024bp_MLL-N_singlelabel_regression_2025-04-26_1510/wandb/wandb/run-20250426_151026-n9pjob5i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/runs/n9pjob5i' target=\"_blank\">run_2025-04-26_1510</a></strong> to <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/sweeps/u4lhvzff' target=\"_blank\">https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/sweeps/u4lhvzff</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF' target=\"_blank\">https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/sweeps/u4lhvzff' target=\"_blank\">https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/sweeps/u4lhvzff</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/runs/n9pjob5i' target=\"_blank\">https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/runs/n9pjob5i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:10:27</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">408</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:10:27\u001b[0m,\u001b[1;36m408\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ece0a9a39546aa90cf722538a09ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:12:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">804</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:12:47\u001b[0m,\u001b[1;36m804\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'embedding_dropout' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gflu_stages' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gflu_dropout' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gflu_feature_init_sparsity' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_epochs' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0973a0f81b446d95eb5e7613e98c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train_loss</td><td>‚ñá‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñá‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÑ‚ñÇ‚ñÑ</td></tr><tr><td>train_mean_squared_error</td><td>‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train_r2_score</td><td>‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>trainer/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>valid_loss</td><td>‚ñÅ‚ñÅ‚ñà‚ñÖ</td></tr><tr><td>valid_mean_squared_error</td><td>‚ñÅ‚ñÅ‚ñà‚ñÖ</td></tr><tr><td>valid_r2_score</td><td>‚ñà‚ñà‚ñÅ‚ñÖ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>train_loss</td><td>0.00467</td></tr><tr><td>train_mean_squared_error</td><td>0.00459</td></tr><tr><td>train_r2_score</td><td>0.89154</td></tr><tr><td>trainer/global_step</td><td>3119</td></tr><tr><td>valid_loss</td><td>0.00396</td></tr><tr><td>valid_mean_squared_error</td><td>0.00396</td></tr><tr><td>valid_r2_score</td><td>0.91008</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_2025-04-26_1510</strong> at: <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/runs/n9pjob5i' target=\"_blank\">https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/runs/n9pjob5i</a><br> View project at: <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF' target=\"_blank\">https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>results/SEM_MLL-N_TF/GANDALF_SEM_promoters_1024bp_MLL-N_singlelabel_regression_2025-04-26_1510/wandb/wandb/run-20250426_151026-n9pjob5i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wze74knp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dropout: 0.1173764817113448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgflu_dropout: 0.04845070125721372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgflu_feature_init_sparsity: 0.2223861472079489\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgflu_stages: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 1.0051682991853323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 139\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'SEM_MLL-N_TF' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>results/SEM_MLL-N_TF/GANDALF_SEM_promoters_1024bp_MLL-N_singlelabel_regression_2025-04-26_1510/wandb/wandb/run-20250426_151851-wze74knp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/runs/wze74knp' target=\"_blank\">run_2025-04-26_1518</a></strong> to <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/sweeps/u4lhvzff' target=\"_blank\">https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/sweeps/u4lhvzff</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF' target=\"_blank\">https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/sweeps/u4lhvzff' target=\"_blank\">https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/sweeps/u4lhvzff</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/runs/wze74knp' target=\"_blank\">https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/runs/wze74knp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:18:52</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">536</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:18:52\u001b[0m,\u001b[1;36m536\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/catherine/GMS/project/models/2025-04-11_gandalf/results/SEM_MLL-N_TF/GANDALF_SEM_promoters_1024bp_MLL-N_singlelabel_regression_2025-04-26_1510/checkpoints exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a5acc10d294620822d8d18f869f8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:20:56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">811</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:20:56\u001b[0m,\u001b[1;36m811\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'embedding_dropout' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gflu_stages' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gflu_dropout' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'gflu_feature_init_sparsity' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'batch_size' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'max_epochs' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c44ca817b304cc9a3ca460c3bd778d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/bs/nx8yhh5s2tn0r0307mtl2mf40000gn/T/ipykernel_27169/43235070.py\", line 66, in train\n",
      "    model.fit(train=train_data, validation=val_data)\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_tabular/tabular_model.py\", line 806, in fit\n",
      "    return self.train(model, datamodule, callbacks, max_epochs, min_epochs, handle_oom)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_tabular/tabular_model.py\", line 680, in train\n",
      "    self.trainer.fit(self.model, train_loader, val_loader)\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1025, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 167, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/core/module.py\", line 1306, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py\", line 153, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py\", line 238, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py\", line 122, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 487, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 91, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/torch/optim/adam.py\", line 202, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py\", line 108, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 129, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 317, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py\", line 390, in training_step\n",
      "    return self.lightning_module.training_step(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_tabular/models/base_model.py\", line 510, in training_step\n",
      "    output, y = self.forward_pass(batch)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_tabular/models/base_model.py\", line 488, in forward_pass\n",
      "    return self(batch), None\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_tabular/models/base_model.py\", line 466, in forward\n",
      "    x = self.compute_backbone(x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_tabular/models/base_model.py\", line 403, in compute_backbone\n",
      "    x = self.backbone(x)\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1844, in _call_impl\n",
      "    return inner()\n",
      "           ^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1790, in inner\n",
      "    result = forward_call(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_tabular/models/gandalf/gandalf.py\", line 65, in forward\n",
      "    return self.gflus(x)\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_tabular/models/common/layers/gated_units.py\", line 69, in forward\n",
      "    feature = self.feature_mask_function(self.feature_masks[d], t[d]) * x\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/catherine/miniforge3/envs/model/lib/python3.11/site-packages/pytorch_tabular/models/common/layers/activations.py\", line 53, in t_softmax\n",
      "    w = torch.relu(input_minus_maxes + t) + 1e-8\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Exception\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà</td></tr><tr><td>train_loss</td><td>‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñá‚ñÜ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÇ‚ñÑ‚ñá‚ñÉ</td></tr><tr><td>train_mean_squared_error</td><td>‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train_r2_score</td><td>‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>trainer/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà</td></tr><tr><td>valid_loss</td><td>‚ñà‚ñÅ‚ñÜ</td></tr><tr><td>valid_mean_squared_error</td><td>‚ñà‚ñÅ‚ñÜ</td></tr><tr><td>valid_r2_score</td><td>‚ñÅ‚ñà‚ñÉ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>train_loss</td><td>0.0037</td></tr><tr><td>train_mean_squared_error</td><td>0.0048</td></tr><tr><td>train_r2_score</td><td>0.88582</td></tr><tr><td>trainer/global_step</td><td>6099</td></tr><tr><td>valid_loss</td><td>0.00398</td></tr><tr><td>valid_mean_squared_error</td><td>0.00398</td></tr><tr><td>valid_r2_score</td><td>0.89634</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_2025-04-26_1518</strong> at: <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/runs/wze74knp' target=\"_blank\">https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/runs/wze74knp</a><br> View project at: <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF' target=\"_blank\">https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>results/SEM_MLL-N_TF/GANDALF_SEM_promoters_1024bp_MLL-N_singlelabel_regression_2025-04-26_1510/wandb/wandb/run-20250426_151851-wze74knp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rpcbf01a with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dropout: 0.1930468698206162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgflu_dropout: 0.10534681707304792\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgflu_feature_init_sparsity: 0.4622232075800971\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgflu_stages: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 1.0077279916387143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epochs: 181\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'SEM_MLL-N_TF' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>results/SEM_MLL-N_TF/GANDALF_SEM_promoters_1024bp_MLL-N_singlelabel_regression_2025-04-26_1510/wandb/wandb/run-20250426_152847-rpcbf01a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/runs/rpcbf01a' target=\"_blank\">run_2025-04-26_1528</a></strong> to <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/sweeps/u4lhvzff' target=\"_blank\">https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/sweeps/u4lhvzff</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF' target=\"_blank\">https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/sweeps/u4lhvzff' target=\"_blank\">https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/sweeps/u4lhvzff</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/runs/rpcbf01a' target=\"_blank\">https://wandb.ai/catherine-chahrour-university-of-oxford/SEM_MLL-N_TF/runs/rpcbf01a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:28:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">388</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.gandalf.gandal<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:109</span><span style=\"font-weight: bold\">}</span> - INFO - Data Aware Initialization of T0    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:28:48\u001b[0m,\u001b[1;36m388\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.gandalf.gandal\u001b[1;92mf:109\u001b[0m\u001b[1m}\u001b[0m - INFO - Data Aware Initialization of T0    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"config/sweep_config.json\", \"r\") as f:\n",
    "    sweep_config = json.load(f)\n",
    "\n",
    "sweep_config[\"name\"] = group\n",
    "sweep_id = wandb.sweep(sweep_config, project=project)\n",
    "wandb.agent(sweep_id=sweep_id, function=train, count=50, project=project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a961b",
   "metadata": {},
   "source": [
    "# üöÇ Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2363a9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(sweep_id)\n",
    "# cwotlgqx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd94bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "sweep = api.sweep(f\"catherine-chahrour-university-of-oxford/{project}/{sweep_id}\")\n",
    "best_run = sorted(\n",
    "    sweep.runs, key=lambda r: r.summary.get(\"valid_r2_score\", 0), reverse=True\n",
    ")[0]\n",
    "config = best_run.config\n",
    "pprint(f\"Best run: {best_run.id} | R¬≤: {best_run.summary['valid_r2_score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbec235",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
